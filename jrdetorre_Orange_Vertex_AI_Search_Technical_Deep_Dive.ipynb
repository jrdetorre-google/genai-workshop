{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "07798920-bf43-4019-b51f-d4307d4abcf1",
      "metadata": {
        "id": "07798920-bf43-4019-b51f-d4307d4abcf1"
      },
      "source": [
        "# Vertex AI Search - Technical Deep Dive - Lab Exercise\n",
        "\n",
        "The purpose of this lab is to explore the use of the client libraries and APIs in Vertex AI Search and the Langchain LLM integrations and retrievers for Enterprise Search and Vertex AI.\n",
        "\n",
        "You'll use these tools to build a question and answer service that takes a user query, retrieves relevant documents from a search data store in Gen App Builder, then returns an LLM-generated answer to the original query along with source documents that were used to generate the answer.\n",
        "\n",
        "Helpful resources for the lab coding exercise:\n",
        "\n",
        "- [Vertex AI Search Code Samples (Documentation)](https://cloud.google.com/generative-ai-app-builder/docs/samples)\n",
        "- [Question Answering Over Documents (GitHub)](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gen-app-builder/retrieval-augmented-generation/examples/question_answering.ipynb)\n",
        "- [Grounding Generative AI using Vertex AI Search Results (Colab)](https://colab.research.google.com/drive/174YYPNNy1rWdIFvV-_LWZ-cueRB7Q6EC?resourcekey=0-9bYTUjXMbEkHIuduaNjNJw&usp=sharing)\n",
        "- [Vertex AI Search - Search Web App (GitHub)](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gen-app-builder/search-web-app)\n",
        "\n",
        "# Coding exercise (Technical asset)\n",
        "\n",
        "## Step 1\n",
        "\n",
        "As a first step, you must create an unstructured data search app that uses PDFs data and get de data_store_id that will be used later.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-AO7-uvKab5e",
      "metadata": {
        "id": "-AO7-uvKab5e"
      },
      "source": [
        "**DONE?** :)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a39aeb7a-c5b6-4086-9045-3811ea41f878",
      "metadata": {
        "id": "a39aeb7a-c5b6-4086-9045-3811ea41f878"
      },
      "source": [
        "## Step 2\n",
        "\n",
        "Install the Vertex AI and Langchain 0.0.236 (newer versions are broken as of 2023-08-10) client libraries for Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "748b3fc0-05b8-4177-aac1-1122c1eda481",
      "metadata": {
        "id": "748b3fc0-05b8-4177-aac1-1122c1eda481",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1702535584449,
          "user_tz": -60,
          "elapsed": 8793,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "# Install packages\n",
        "# Note: You might need to restart the runtime after installing these packages\n",
        "#!pip install google-cloud-discoveryengine google-cloud-aiplatform langchain==0.0.236 \"shapely<2.0.0\" -q\n",
        "!pip install google-cloud-discoveryengine google-cloud-aiplatform langchain -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio==3.48.0 -q"
      ],
      "metadata": {
        "id": "AxK1bWn2K3e4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1702534653368,
          "user_tz": -60,
          "elapsed": 8358,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "AxK1bWn2K3e4",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "aywVLgBGis9x",
      "metadata": {
        "id": "aywVLgBGis9x"
      },
      "source": [
        "Next code will restart your Runtime\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "inIUNlEGYdoa",
      "metadata": {
        "id": "inIUNlEGYdoa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1702535372897,
          "user_tz": -60,
          "elapsed": 933,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2958b872-9131-4c66-9e97-ff530ebd5af3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Killing tunnel 127.0.0.1:7860 <> https://aa45d9ef32a90f9b32.gradio.live\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f45fbdee-f84f-4b2b-856f-92c665b12667",
      "metadata": {
        "id": "f45fbdee-f84f-4b2b-856f-92c665b12667"
      },
      "source": [
        "## Step 3\n",
        "\n",
        "Use the [Vertex AI Search document retriever in LangChain](https://python.langchain.com/docs/integrations/retrievers/google_vertex_ai_search) to retrieve documents from your data store based on a query.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we introduce the project ID where we will run the cloud services, the location and Data Store ID previously created."
      ],
      "metadata": {
        "id": "pO2SMUkTyJFe"
      },
      "id": "pO2SMUkTyJFe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab5bfaf5-afb2-4aab-93ab-dbe4018b62ee",
      "metadata": {
        "id": "ab5bfaf5-afb2-4aab-93ab-dbe4018b62ee",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Configuration Variables and Test Retriever\n",
        "PROJECT_ID = \"qwiklabs-gcp-02-95597416198e\" # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
        "DATA_STORE_ID = \"orange-pdf_1702533306233\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And start the execution"
      ],
      "metadata": {
        "id": "AS_UEXPlykHC"
      },
      "id": "AS_UEXPlykHC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate with Google account\n",
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()"
      ],
      "metadata": {
        "id": "4XOJ6ts3E0Jd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1702535394507,
          "user_tz": -60,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "4XOJ6ts3E0Jd",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5cc27275-46ce-4455-93e2-3fb4798e0a00",
      "metadata": {
        "id": "5cc27275-46ce-4455-93e2-3fb4798e0a00",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1702535396884,
          "user_tz": -60,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "from os.path import basename\n",
        "from typing import Dict, List, Optional, Tuple, Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1702535801011,
          "user_tz": -60,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e8a55659-54c9-4ffa-87f3-e028818780ec",
        "id": "y5VgC7Rf6tpY"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='FY22 results\\n\\n9\\n\\nEBITDAaL\\nreaching\\n€13bn in line\\nwith guidance\\n\\n9\\n\\nGroup\\nEBITDAaL\\n\\nyoy\\n+8.5%\\n+€269m\\n\\nyoy\\n+2.5%\\n+€318m\\n\\n92\\n\\n262\\n\\n19\\n\\n13\\n\\n141\\n\\nSpain\\n\\n12,963\\n\\n25\\n\\nFY 21 cb France\\n\\nTotem\\n\\nMobile\\nFinancial\\nServices\\n\\nEnterprise\\n\\nFY 22\\n\\n-186\\n\\nOther\\n\\nMEA\\n\\nICSS**\\n\\nEuropeans\\ncountries\\n\\n-47\\n\\n12,645\\n\\nFY 2022 Group EBITDAaL evolution per segment (yoy, in€m)\\n\\nTelecom*\\nEBITDAaL\\n\\nyoy\\n+7.9%\\n+€256m\\n\\nyoy\\n+2.4%\\n+€306m\\n\\n+0.4%\\n\\n-4.0%\\n\\n-18.8%\\n\\n+5.8%\\n\\n+5.4%\\n\\n* The Mobile Financial Services business segment includes the activities of Orange Bank and Orange Bank Africa (with Orange Money business reported under MEA segment).\\n** International CarrIers and Shared Services\\n\\nQ4 2022\\n\\nFY 2022\\n\\n+11.3%\\n\\n+10.0%\\n\\n+2.5%\\n\\n+59.7%' metadata={'id': 'd8d4ab56eae856a1156c2b83a91c456e', 'source': 'gs://jrdetorre-orange-demo/Orange-Q4 2022 Financial Results.pdf'}\n"
          ]
        }
      ],
      "source": [
        "# from google.cloud import discoveryengine as discoveryengine\n",
        "from langchain.retrievers import (\n",
        "    GoogleVertexAISearchRetriever\n",
        ")\n",
        "QUERY = \"Quien es el CEO de Orange?\"\n",
        "\n",
        "# Code your solution here\n",
        "\n",
        "# Initialise an Vertex AI Search Retriever\n",
        "retriever = GoogleVertexAISearchRetriever(\n",
        "    project_id=PROJECT_ID,\n",
        "    search_engine_id=DATA_STORE_ID\n",
        "    #,max_documents=3 #opt\n",
        "    #,max_extractive_answer_count=3, #opt\n",
        "    ,get_extractive_answers=True #opt\n",
        "    )\n",
        "# Get relevant documents\n",
        "result = retriever.get_relevant_documents(QUERY)\n",
        "for doc in result:\n",
        "    print(doc)\n"
      ],
      "id": "y5VgC7Rf6tpY"
    },
    {
      "cell_type": "markdown",
      "id": "22426eb0-0b76-4784-90d2-3f6dda60ec12",
      "metadata": {
        "id": "22426eb0-0b76-4784-90d2-3f6dda60ec12"
      },
      "source": [
        "## Step 4\n",
        "\n",
        "Given a search query, use [Langchain's LLM integration with Vertex AI](https://python.langchain.com/docs/integrations/llms/google_vertex_ai_palm) to send a search query and return an answer with source documents\n",
        "\n",
        "Hint: Use [RetrievalQAWithSourcesChain](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gen-app-builder/retrieval-augmented-generation/examples/question_answering.ipynb) and refer to the “Helpful resources” at the top of this notebook!\n",
        "\n",
        "Sample query: “Who is the CEO of DeepMind?”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "42594d94-5c92-4491-adb4-4b8f7e891e70",
      "metadata": {
        "id": "42594d94-5c92-4491-adb4-4b8f7e891e70",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1702535448145,
          "user_tz": -60,
          "elapsed": 8366,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "from langchain.llms import VertexAI\n",
        "#from langchain.retrievers import GoogleVertexAISearchRetriever\n",
        "\n",
        "# Code your solution here\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define the parameters for LLM model calls"
      ],
      "metadata": {
        "id": "oydUHs8tT7dF"
      },
      "id": "oydUHs8tT7dF"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "Zr061mAseB6C",
      "metadata": {
        "id": "Zr061mAseB6C",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1702535810622,
          "user_tz": -60,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "#Initialise LLM\n",
        "LLM_MODEL = \"text-bison@001\" #@param {type: \"string\"}\n",
        "MAX_OUTPUT_TOKENS = 1024 #@param {type: \"integer\"}\n",
        "TEMPERATURE = 0.2 #@param {type: \"number\"}\n",
        "TOP_P = 0.8 #@param {type: \"number\"}\n",
        "TOP_K = 40 #@param {type: \"number\"}\n",
        "VERBOSE = True #@param {type: \"boolean\"}\n",
        "llm_params = dict(\n",
        "    model_name=LLM_MODEL,\n",
        "    max_output_tokens=MAX_OUTPUT_TOKENS,\n",
        "    temperature=TEMPERATURE,\n",
        "    top_p=TOP_P,\n",
        "    top_k=TOP_K,\n",
        "    verbose=VERBOSE,\n",
        ")\n",
        "\n",
        "llm = VertexAI(**llm_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample question for testing"
      ],
      "metadata": {
        "id": "T4dcM7-9ULa7"
      },
      "id": "T4dcM7-9ULa7"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "guDxsD8DhVdi",
      "metadata": {
        "id": "guDxsD8DhVdi",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1702535812826,
          "user_tz": -60,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "QUERY = \"Quien es el CEO de Orange?\" #@param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we test the results before productivicing\n"
      ],
      "metadata": {
        "id": "1g_OSrQ5UPcx"
      },
      "id": "1g_OSrQ5UPcx"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "dOraYXJYfBHh",
      "metadata": {
        "id": "dOraYXJYfBHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1702535819614,
          "user_tz": -60,
          "elapsed": 1297,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "fc53bc77-2ed1-4de7-b537-63f210dc4f0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mPlease parse these search results and summarize them to the answer the following question. Results:['FY22 results\\n\\n9\\n\\nEBITDAaL\\nreaching\\n€13bn in line\\nwith guidance\\n\\n9\\n\\nGroup\\nEBITDAaL\\n\\nyoy\\n+8.5%\\n+€269m\\n\\nyoy\\n+2.5%\\n+€318m\\n\\n92\\n\\n262\\n\\n19\\n\\n13\\n\\n141\\n\\nSpain\\n\\n12,963\\n\\n25\\n\\nFY 21 cb France\\n\\nTotem\\n\\nMobile\\nFinancial\\nServices\\n\\nEnterprise\\n\\nFY 22\\n\\n-186\\n\\nOther\\n\\nMEA\\n\\nICSS**\\n\\nEuropeans\\ncountries\\n\\n-47\\n\\n12,645\\n\\nFY 2022 Group EBITDAaL evolution per segment (yoy, in€m)\\n\\nTelecom*\\nEBITDAaL\\n\\nyoy\\n+7.9%\\n+€256m\\n\\nyoy\\n+2.4%\\n+€306m\\n\\n+0.4%\\n\\n-4.0%\\n\\n-18.8%\\n\\n+5.8%\\n\\n+5.4%\\n\\n* The Mobile Financial Services business segment includes the activities of Orange Bank and Orange Bank Africa (with Orange Money business reported under MEA segment).\\n** International CarrIers and Shared Services\\n\\nQ4 2022\\n\\nFY 2022\\n\\n+11.3%\\n\\n+10.0%\\n\\n+2.5%\\n\\n+59.7%']. Question:Quien es el CEO de Orange?. Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The CEO of Orange is Stéphane Richard.']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Combine the LLM with a prompt to make a simple chain\n",
        "PROMPT_STRING = \"Please parse these search results and summarize them to the answer the following question. Results:{results}. Question:{query}. Answer:\"\n",
        "prompt = PromptTemplate(input_variables=['results', 'query'],\n",
        "                        template=PROMPT_STRING)\n",
        "chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
        "\n",
        "# Get relevant documents\n",
        "documents = retriever.get_relevant_documents(QUERY)\n",
        "content = [d.page_content for d in documents]\n",
        "\n",
        "# Use the LLM-prompt chain to answer the question based on the results\n",
        "result = chain.run({'results': content, 'query': QUERY})\n",
        "\n",
        "result.split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQUkzY4KAHGm",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1702535825846,
          "user_tz": -60,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "a1a983a9-45d0-438a-cbb0-6d4f7524283c"
      },
      "id": "NQUkzY4KAHGm",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['FY22 results\\n\\n9\\n\\nEBITDAaL\\nreaching\\n€13bn in line\\nwith guidance\\n\\n9\\n\\nGroup\\nEBITDAaL\\n\\nyoy\\n+8.5%\\n+€269m\\n\\nyoy\\n+2.5%\\n+€318m\\n\\n92\\n\\n262\\n\\n19\\n\\n13\\n\\n141\\n\\nSpain\\n\\n12,963\\n\\n25\\n\\nFY 21 cb France\\n\\nTotem\\n\\nMobile\\nFinancial\\nServices\\n\\nEnterprise\\n\\nFY 22\\n\\n-186\\n\\nOther\\n\\nMEA\\n\\nICSS**\\n\\nEuropeans\\ncountries\\n\\n-47\\n\\n12,645\\n\\nFY 2022 Group EBITDAaL evolution per segment (yoy, in€m)\\n\\nTelecom*\\nEBITDAaL\\n\\nyoy\\n+7.9%\\n+€256m\\n\\nyoy\\n+2.4%\\n+€306m\\n\\n+0.4%\\n\\n-4.0%\\n\\n-18.8%\\n\\n+5.8%\\n\\n+5.4%\\n\\n* The Mobile Financial Services business segment includes the activities of Orange Bank and Orange Bank Africa (with Orange Money business reported under MEA segment).\\n** International CarrIers and Shared Services\\n\\nQ4 2022\\n\\nFY 2022\\n\\n+11.3%\\n\\n+10.0%\\n\\n+2.5%\\n\\n+59.7%']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we create a function that will be called from Gradio"
      ],
      "metadata": {
        "id": "gkDh0uQ2UjfE"
      },
      "id": "gkDh0uQ2UjfE"
    },
    {
      "cell_type": "code",
      "source": [
        "def data_store_qna(QUERY):\n",
        "\n",
        "  PROMPT_STRING = \"Please parse these search results and summarize them to the answer the following question. Results:{results}. Question:{query}. Answer:\"\n",
        "  prompt = PromptTemplate(input_variables=['results', 'query'],\n",
        "                        template=PROMPT_STRING)\n",
        "  chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
        "\n",
        "# Get relevant documents\n",
        "  documents = retriever.get_relevant_documents(QUERY)\n",
        "  content = [d.page_content for d in documents]\n",
        "\n",
        "# Use the LLM-prompt chain to answer the question based on the results\n",
        "  result = chain.run({'results': content, 'query': QUERY})\n",
        "\n",
        "  result.split('\\n')\n",
        "  return result"
      ],
      "metadata": {
        "id": "MkKQ35V8HT30",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1702535731437,
          "user_tz": -60,
          "elapsed": 855,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "MkKQ35V8HT30",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the function"
      ],
      "metadata": {
        "id": "bNXiprHtUv6i"
      },
      "id": "bNXiprHtUv6i"
    },
    {
      "cell_type": "code",
      "source": [
        "output=data_store_qna(QUERY)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "iHlDr-QmJD7_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1702535063633,
          "user_tz": -60,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "2136fe58-9fc7-42d0-dc62-1bbad39d5b03"
      },
      "id": "iHlDr-QmJD7_",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mPlease parse these search results and summarize them to the answer the following question. Results:['FY22 results\\n\\n9\\n\\nEBITDAaL\\nreaching\\n€13bn in line\\nwith guidance\\n\\n9\\n\\nGroup\\nEBITDAaL\\n\\nyoy\\n+8.5%\\n+€269m\\n\\nyoy\\n+2.5%\\n+€318m\\n\\n92\\n\\n262\\n\\n19\\n\\n13\\n\\n141\\n\\nSpain\\n\\n12,963\\n\\n25\\n\\nFY 21 cb France\\n\\nTotem\\n\\nMobile\\nFinancial\\nServices\\n\\nEnterprise\\n\\nFY 22\\n\\n-186\\n\\nOther\\n\\nMEA\\n\\nICSS**\\n\\nEuropeans\\ncountries\\n\\n-47\\n\\n12,645\\n\\nFY 2022 Group EBITDAaL evolution per segment (yoy, in€m)\\n\\nTelecom*\\nEBITDAaL\\n\\nyoy\\n+7.9%\\n+€256m\\n\\nyoy\\n+2.4%\\n+€306m\\n\\n+0.4%\\n\\n-4.0%\\n\\n-18.8%\\n\\n+5.8%\\n\\n+5.4%\\n\\n* The Mobile Financial Services business segment includes the activities of Orange Bank and Orange Bank Africa (with Orange Money business reported under MEA segment).\\n** International CarrIers and Shared Services\\n\\nQ4 2022\\n\\nFY 2022\\n\\n+11.3%\\n\\n+10.0%\\n\\n+2.5%\\n\\n+59.7%']. Question:Quien es el CEO de Orange?. Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " The provided text does not mention the CEO of Orange.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We import Gradio and create a simple website. It will provide us with an URL that we can use to test it."
      ],
      "metadata": {
        "id": "3YxY6MvYU1pv"
      },
      "id": "3YxY6MvYU1pv"
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    ## Ask Vertex AI Search\n",
        "\n",
        "    This app uses Vertex AI Search Results to answer questions.\n",
        "\n",
        "    ## How to use\n",
        "\n",
        "    1. Enter a question\n",
        "    2. Click on \"Ask the Question\"\n",
        "    3. The answer will be displayed\n",
        "\n",
        "    \"\"\")\n",
        "    with gr.Row():\n",
        "      with gr.Column():\n",
        "        input_text = gr.Textbox(label=\"Question\", placeholder=\"Quién es el CEO de Orange?\")\n",
        "    with gr.Row():\n",
        "      generate = gr.Button(\"Ask the Question\")\n",
        "    with gr.Row():\n",
        "      label = gr.Textbox(label=\"Output\")\n",
        "    generate.click(data_store_qna,input_text, [label])\n",
        "demo.launch(share=True, debug=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "XpCkt713MSJk",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1702535859803,
          "user_tz": -60,
          "elapsed": 4500,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "5f33ad03-663e-4f1c-ee25-bff63c1ba43f"
      },
      "id": "XpCkt713MSJk",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://b4782df23e582faf97.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b4782df23e582faf97.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mCUHDXDfOakI"
      },
      "id": "mCUHDXDfOakI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}